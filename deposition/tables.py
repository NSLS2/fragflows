import pandas as pd
import os
import uuid
from pathlib import Path
from validation.statistics import *
from deposition.structure import make_structure_from_block_wrapper
import numpy as np
import traceback


def generate_refinement_table(
    export_dir: str,
    dataset_csv: str,
    ligand_csv: str,
    basename: str = "refine",
    basename_hkl: str = "reflections",
):
    """Loop through the pandda.export directory and build a table containing filepaths for refined
    structure and corresponding reflection cifs. Ligand information is included for each crystal,
    because this information is required for each final changed state structure cif."""

    result_list = []
    ligand_df = pd.read_csv(ligand_csv)
    dataset_df = pd.read_csv(dataset_csv)

    # the most recently modified reflection/structure cif file is considered to be the final file

    for d in os.listdir(export_dir):
        data_dir = Path(Path(export_dir) / Path(d))
        refine_cifs = [
            f
            for f in data_dir.iterdir()
            if (basename in f.name and f.is_file() and f.name.endswith("cif"))
        ]
        refine_cifs = sorted(refine_cifs, key=lambda f: f.stat().st_mtime, reverse=True)
        result_dict = {
            "uid": str(uuid.uuid4()),
            "xtal_id": d,
            "refined_structure_file": next(
                (str(f) for f in refine_cifs if basename_hkl not in f.name), None
            ),
            "refined_reflection_file": next(
                (str(f) for f in refine_cifs if basename_hkl in f.name), None
            ),
            "reflection_data_file": dataset_df.loc[
                dataset_df["xtal_id"] == d, "filepath"
            ].iloc[0],
            "smiles": ligand_df.loc[ligand_df["xtal_id"] == d, "smiles"].iloc[0],
            "catalog_id": ligand_df.loc[ligand_df["xtal_id"] == d, "catalog_id"].iloc[
                0
            ],
        }
        result_list.append(result_dict)

    df = pd.DataFrame(result_list)
    return df


def generate_event_table(
    export_dir: str, pandda_event_csv: str, refinement_table_csv: str
):
    """There is a many-to-one relationship between events and xtal_ids in that there can be multiple
    events for a single dataset. Each event has a corresponding BDC-corrected ccp4 map file generated by
    pandda. These separate events are converted into cif blocks and appened to the changed state structure
    factor cif file. Again the pandda.export directory is the ground truth of what is considered a changed state.
    We impose an additional filter, based on Ligand Confidence assigned during inspect, to determine whether
    or not to include the event/ligand."""

    # left join the refinement table with the pandda inspect event table and filter pertinent information
    # for group deposition

    df1 = pd.read_csv(refinement_table_csv)
    df2 = pd.read_csv(pandda_event_csv)
    df2 = df2.rename(columns={"dtag": "xtal_id"})
    df_merged = df1.merge(df2, on="xtal_id", how="left")

    result_list = []

    for idx, row in df_merged.iterrows():
        event_map_file = None
        try:
            single_export_dir = Path(export_dir) / Path(row["xtal_id"])
            event_map_file = next(
                (
                    str(f)
                    for f in single_export_dir.iterdir()
                    if f.is_file()
                    and f"event_{row['event_idx']}" in f.name
                    and f.name.endswith("ccp4")
                ),
                None,
            )
        except Exception as e:
            print(f"problem finding event_map file for {row['xtal_id']}: {e}")

        result_dict = {
            "uid": str(uuid.uuid4()),
            "xtal_id": row["xtal_id"],
            "event_idx": row["event_idx"],
            "1-BDC": row["1-BDC"],
            "event_map_file": event_map_file,
            "xtal_uid": row["uid"],
            "x": row["x"],
            "y": row["y"],
            "z": row["z"],
        }

        if row["Ligand Placed"] == True and row["Ligand Confidence"] == "High":
            result_list.append(result_dict)

    df = pd.DataFrame(result_list)
    return df


def generate_refinement_validation_table(
    refinement_table_csv: str,
    event_table_csv: str,
    basename: str = "ensemble",
    ligand_name: str = "UNL",
):
    refinement_df = pd.read_csv(refinement_table_csv)
    event_df = pd.read_csv(event_table_csv)

    result_list = []
    for _, row in refinement_df.iterrows():
        try:
            structure_doc = gemmi.cif.read_file(row["refined_structure_file"])
            print(row["refined_structure_file"])
            print(structure_doc)
            print(structure_doc[0].name)
            structure_block = [
                block for block in structure_doc if basename in block.name
            ][0]
            st = make_structure_from_block_wrapper(structure_block)
            rblock = gemmi.as_refln_blocks(
                gemmi.cif.read(row["refined_reflection_file"])
            )[0]
            for model in st:
                for chain in model:
                    for residue in chain:
                        if residue.name == ligand_name:
                            real_space_mean, real_space_var, real_space_cc = (
                                real_space_map_stats(st, rblock, residue)
                            )
                            lig_coords = np.mean(
                                np.array(
                                    [
                                        [atom.pos.x, atom.pos.y, atom.pos.z]
                                        for atom in residue
                                    ]
                                ),
                                axis=0,
                            )
                            events = event_df[event_df["xtal_id"] == row["xtal_id"]]
                            event_coords = events[["x", "y", "z"]].values
                            event_distances = np.linalg.norm(
                                event_coords - lig_coords, axis=1
                            )
                            nearest_event_no_pbc = events.iloc[
                                event_distances.argmin()
                            ]["uid"]

                            result_dict = {
                                "uid": str(uuid.uuid4()),
                                "xtal_uid": row["uid"],
                                "xtal_id": row["xtal_id"],
                                "chain_id": chain.name,
                                "residue_name": residue.name,
                                "seqid": residue.seqid,
                                "real_space_mean": real_space_mean,
                                "real_space_var": real_space_var,
                                "real_space_cc": real_space_cc,
                                "diff_z_score": real_space_diff_zscore(
                                    st, rblock, residue
                                ),
                                "lig_prot_b_iso_ratio": lig_prot_b_iso_ratio(
                                    st, residue
                                ),
                                "nearest_event_no_pbc": nearest_event_no_pbc,
                                "dist_to_nearest_event": np.min(event_distances),
                            }
                            result_list.append(result_dict)
        except Exception as e:
            print(f"Caught exception {e} for {row['xtal_id']}")
            traceback.print_exc()
    return pd.DataFrame(result_list)
